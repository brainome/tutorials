{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfebebd9",
   "metadata": {},
   "source": [
    "![](https://www.brainome.ai/wp-content/uploads/2020/08/brainome_logo.png)\n",
    "# 201 Capacity Progression (CP)\n",
    "\n",
    "\n",
    "1. What is Capacity Progression\n",
    "2. Measuring CP\n",
    "3. Measuring while adjusting data splits\n",
    "4. Finding your data's content sweet spot \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789010a0",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "This notebook assumes brainome is installed as per notebook [brainome_101_Quick_Start](brainome_101_Quick_Start.ipynb)\n",
    "\n",
    "The data sets are:\n",
    "* [data/titanic_train.csv](data/titanic_train.csv) for training data\n",
    "* [data/titanic_validate.csv](data/titanic_validate.csv) for validation\n",
    "* [data/titanic_predict.csv](data/titanic_predict.csv) for predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33177319",
   "metadata": {},
   "source": [
    "## 1. What is Capacity Progression\n",
    "*Capacity progression measures the learnability of a dataset, by plotting the number of decisions needed to memorize the function presented by the training data relative to the number of instances presented to the predictor  (for an ideal model).*\n",
    "\n",
    "From the [Brainome Glossary](https://www.brainome.ai/documentation/glossary/#Capacity%20Progression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f889a13",
   "metadata": {},
   "source": [
    "## 2. Measuring Capacity Progression\n",
    "Brainome outputs the CP measurements of an ideal machine learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de2aa21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\r\n",
      "    Ideal Machine Learner:              6,   7,   8,   8,   9,   9\r\n"
     ]
    }
   ],
   "source": [
    "!brainome data/titanic_train.csv -y -measureonly -json report_201_measureonly.json | grep -A 1 Capacity -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72975533",
   "metadata": {},
   "source": [
    "## 3.  Measuring while adjusting data splits\n",
    "The **-split** parameter instructs brainome that percent of the data for training, and the rest for validation\n",
    "\n",
    "By measuring the predictor at various split points, you can see how much data is really necessary to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f7c9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splits = range(10, 100, 10)\n",
    "for s in splits:\n",
    "    !brainome data/titanic_train.csv -y -f DT -split {s} -json report_201_split_{s}.json -modelonly -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2325ad",
   "metadata": {},
   "source": [
    "## Processing the measurements\n",
    "Each of the previous runs created a json report from which we extract the MEC, Training Accuracy, and Validation Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfbf5913",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import json\n",
    "# extract CP from measureonly run\n",
    "with open('report_201_measureonly.json', 'r') as measures:\n",
    "    measures = json.load(measures)\n",
    "    capacity = measures['session']['datameter']['capacity_progression']['value']\n",
    "\n",
    "# extract MEC and accuracies from split runs\n",
    "samples = []\n",
    "for split_file in [Path(p) for p in glob('report_201_split_*.json')]:\n",
    "    # split pct is in filename\n",
    "    split_pct = int(split_file.stem[17:])\n",
    "    with open(split_file, 'r') as r_file:\n",
    "        # load split run results\n",
    "        split_report = json.load(r_file)\n",
    "        # extract specific measurements from results\n",
    "        samples.append((split_pct, \n",
    "                        split_report['session']['system_meter'].get('model_capacity'),\n",
    "                        split_report['session']['system_meter'].get('train_accuracy'),\n",
    "                        split_report['session']['system_meter'].get('validation_accuracy')\n",
    "                       ))\n",
    "# sort samples by integer split percentage\n",
    "samples.sort(key = lambda x: x[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715fee81",
   "metadata": {},
   "source": [
    "## 4. Finding your training data's content sweet spot \n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a727df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capacity Progression:\n",
      "[ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "[6, 7, 8, 8, 9, 9]\n",
      "\n",
      "\n",
      "Split %\t\tMEC\t\tTrain Acc\tValidate Acc\n",
      "-------\t\t---\t\t---------\t------------\n",
      "10\t\t36\t\t100.0\t\t54.5\n",
      "20\t\t78\t\t100.0\t\t55.07\n",
      "30\t\t114\t\t100.0\t\t54.9\n",
      "40\t\t160\t\t100.0\t\t54.88\n",
      "50\t\t198\t\t100.0\t\t54.25\n",
      "60\t\t236\t\t100.0\t\t54.82\n",
      "70\t\t266\t\t100.0\t\t53.52\n",
      "80\t\t304\t\t100.0\t\t54.65\n",
      "90\t\t342\t\t100.0\t\t56.79\n"
     ]
    }
   ],
   "source": [
    "print(\"Capacity Progression:\")\n",
    "print(\"[ 5%, 10%, 20%, 40%, 80%, 100% ]\")\n",
    "print(capacity)\n",
    "print('\\n')\n",
    "print(\"Split %\\t\\tMEC\\t\\tTrain Acc\\tValidate Acc\")\n",
    "print(\"-------\\t\\t---\\t\\t---------\\t------------\")\n",
    "for sample in samples:\n",
    "    print(f\"{sample[0]}\\t\\t{sample[1]}\\t\\t{sample[2]}\\t\\t{sample[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e36fb88",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Check out [brainome_202_MEC](./brainome_202_MEC.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
